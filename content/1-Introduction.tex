\chapter{Introduction}
\label{ch:intro}
Discrete integration is a fundamental problem in artificial intelligence, with applications in probabilistic reasoning, planning, inexact computing, engineering reliability, and statistical physics \cite{Bacchus2003,DH07,GSS08,naveh2007constraint}. In discrete integration, the task is to count the total weight, subject to a given weight function, of the set of solutions of input constraints \cite{GSS08}. 
If the input constraints are given as a propositional formula, the problem is called \emph{model counting}. 
If existential variables are also allowed in the input constraints, the problem is called \emph{projected model counting}. This thesis primarily focuses on exact techniques for model counting and projected model counting, but other works have considered other classes of discrete integration problems (e.g., allowing constraints with alternating quantifiers \cite{stearns2002exploiting,KNR16}, or allowing continuous variables \cite{BPV15}) or approximate techniques \cite{CMV21}.

As is common, we restrict our attention to discrete integration problems where the weight function is log-linear (i.e., literal-weighted), which captures a wide variety of probabilistic distributions~\cite{KF09}.
% For example, in the context of probabilistic reasoning this corresponds to assuming that all variables are independent.
% Log-linear models can be employed to capture a wide variety of probabilistic distributions that arise from graphical models, conditional random fields, skip-gram models, and the like~\cite{KF09}. %TODO: Check sentence from WMC-reduction paper.
We call a discrete integration problem \emph{weighted} if the weight function is log-linear and \emph{unweighted} if the weight function is a constant function (and thus the task is simply to count the number of solutions to the input constraints).
Note that unweighted discrete integration is a special case of weighted discrete integration.
Unweighted model counting is also called \#SAT, while unweighted projected model counting is also called $\#\exists$SAT.

Even the simplest case of discrete integration, \#SAT, is \#P-Complete \cite{Valiant79}. 
In fact, every problem in the polynomial hierarchy can be answered by a single \#SAT query \cite{toda89}. 
As a simple example, a propositional formula is satisfiable if and only if its unweighted model count is nonzero.
Weighted model counting (with rational, log-linear weights) is \#P-Complete as well, through a reduction to \#SAT that encodes the weights in additional variables \cite{CFMV15,DFM20}.
But projected model counting is thought to be harder: $\#\exists$SAT is not contained in $\#$P unless the polynomial hierarchy collapses to $\Sigma_2^P$ \cite{zawadzki2013generalization}.

Despite the theoretical difficulty of discrete integration, a variety of discrete integration tools (called \emph{counters}) exist that can handle industrial sets of constraints. The earliest counters, e.g. \tool{CDP} \cite{birnbaum1999good}, were based on search.
The key idea is to take an algorithm for exploring the entire solution space of a set of constraints (e.g. DPLL \cite{davis1960computing,davis1962machine}, and later CDCL \cite{biere2009conflict}) and augment it to enumerate the number of partial solutions encountered. 
Modern solvers such as \tool{cachet} \cite{SBK05} and \tool{SharpSAT} \cite{Thurley2006} follow this approach.
Another class of counters (e.g. \tool{miniC2D} \cite{OD15} and \tool{d4} \cite{LM17}) are based on knowledge compilation, where the idea is to compile the set of constraints into an alternative representation on which a discrete integration query may be answered in polynomial time.

A third class of counters \cite{CW16,FHMW17,FHWZ18,FHZ19,DPV20,fichte2020exploiting} are based on dynamic programming. % \cite{BDP09,SS10,jegou2016improving} % TODO: should cite Algorithms \cite{FMR08,SS10}.
Dynamic programming is a powerful technique that has been applied across computer science \cite{bellman1966dynamic}, including to database-query optimization \cite{MPPV04}, satisfiability solving \cite{uribe1994ordered,aguirre2001random,pan2005symbolic}, and QBF evaluation \cite{charwat2016bdd}.
The key idea is to solve a sequence of smaller subproblems, formed by partitioning the input constraints, and then incrementally combine these solutions into the final result.
The techniques developed in this thesis are all based on dynamic programming.

The key idea of this thesis is that dynamic-programming algorithms for discrete integration can be cleanly separated into two phases: a \emph{planning phase} of high-level reasoning to construct subproblems, followed by an \emph{execution phase} of low-level computation which solves subproblems.
Existing dynamic-programming-based counters perform both high-level reasoning and low-level planning, but in an intermixed way that is tightly coupled to a single existing library.
Explicitly separating planning and execution enables us to separately reason about, implement, and optimize each stage.
Instead of building tightly on any particular library, we target APIs that can be fulfilled by multiple planning or execution implementations.
The resulting counters scale to large problem instances and run flexibly in a variety of hardware environments.

% This requires novel theoretical and algorithmic techniques to use existing high-level reasoning tools in a way consistent with the options available in popular low-level computational libraries. 
 
% The requirements, challenges, and opportunities of each phase are often dramatically different, both at an algorithmic and an implementation level.  

% This thesis argues that this separation enables the resulting counters to scale to large problem instances and run flexibly in a variety of hardware environments.


% \tool{cachet} \cite{SBK05} and \tool{SharpSAT} \cite{Thurley2006} are modern solvers that are also based on search.
%In counters based on direct reasoning (e.g., \tool{cachet} \cite{SBK05}), the idea is to reason directly about the CNF representation of $\varphi$. In counters based on knowledge compilation (e.g. \tool{miniC2D} \cite{OD15} and \tool{d4} \cite{LM17}), the idea is to compile $\varphi$ into an alternative representation on which counting is easy. In counters based on dynamic programming (e.g. \tool{ADDMC} \cite{DPV20} and \tool{gpuSAT2} \cite{FHWZ18,FHZ19}), the idea is to traverse the clause structure of $\varphi$. Tensor-network approaches to counting (e.g. \tool{TensorOrder} \cite{DDV19} and this work) are also based on dynamic programming. Dynamic programming approaches often utilize graph decompositions, which we define in the next section. 

% $\#\exists$SAT is complete for the complexity class \#P\textsuperscript{NP[1]}, which is the set of counting problems 
% (solvable by a polynomially bounded counting Turing machine with one query to an NP-complete oracle)
% \cite{zawadzki2013generalization}

% Even when the weight function is a constant function, constrained counting is \#P-Complete \cite{Valiant79}. 

% Nevertheless, a variety of tools exist that can handle industrial sets of constraints, \eg, \cite{sang2004combining,OD15,darwiche2004new,LM17}. 

% Log-linear models are employed to capture a wide variety of distributions that arise from graphical models, conditional random fields, skip-gram models, and the like~\cite{KF09}.


\section{Planning: High-Level Reasoning}
In the planning phase, we aim to leverage graph decompositions as a tool for high-level reasoning. \emph{Graph decompositions} \cite{halin1976s,robertson1984graph,RS91,ST94} aim to decompose a graph into subgraphs in such a way that the decomposition can aid algorithms running on the graph.
% Thus a graph decomposition crystallizes a particular strategy for reasoning on the graph.
For example, a \emph{tree decomposition} \cite{halin1976s,robertson1984graph} decomposes a graph into a tree structure that captures information on graph cycles.
Algorithms based on graph decompositions have been successful across computer science \cite{GLST17,MPPV04}.

The success of graph-decomposition algorithms in practice relies on finding good decompositions of arbitrary graphs.
This has spurred the development of a variety of heuristics and tools for efficiently finding graph decompositions \cite{AMW17,HS18,Tamaki17,hicks02}. 
Moreover, recent competitions \cite{DKTW18} ensured that many graph decomposition tools can be used through a single unified API and thus, with careful design, can be interchanged.

A variety of dynamic-programming algorithms \cite{FMR08,SS10} and counters \cite{CW16,FHMW17,FHWZ18,FHZ19} exist for performing discrete integration using graph decompositions.
These counters are typically closely integrated with a a single graph-decomposition tool.
For example \tool{gpuSAT2} \cite{FHWZ18,FHZ19} is a tool for weighted model counting that is closely integrated with the tree-decomposition solver \pkg{htd} \cite{AMW17}. While \tool{gpuSAT2} also includes some low-level computational optimizations, it uses handwritten GPU kernel calls instead of leveraging low-level computational libraries.


\section{Execution: Low-Level Computation}
\label{sec:intro:execution}
In the execution phase, we aim to leverage two existing classes of low-level computational libraries: tensors and decision diagrams. 

\emph{Tensors} are a tool used across quantum physics and computer science for describing and reasoning about quantum systems, big-data processing, and more \cite{BB17,Cichocki14,Orus19}.
Contraction is a key operation in neural network training and inference \cite{BK07,Hirata03,KKCLA17,VZTGDMVAC18}.
Consequently, there is massive practical work across machine learning and high-performance computing on tensor contraction \cite{BK07,Hirata03,KKCLA17,VZTGDMVAC18} (often with support for GPUs \cite{KSTKPPRS19,NRBHHJN15} or other specialized hardware \cite{JYPPABBBBB17}).
This includes a variety of high-performance libraries that can perform tensor contraction \cite{numpy,ABCCDDDGII16,PGMLJGKLGA19} in a variety of hardware settings with a single unified API. 
% While one work \cite{KCMR18} has applied these libraries towards discrete integration, the high-level reasoning was limited to several heuristics.
% These libraries have only seen limited application towards discrete integration  \cite{KCMR18}.

\emph{Decision diagrams} are a group of data structures used to sparsely represent sets and functions \cite{akers1978binary,bahar1997algebraic,minato1993zero,sanner2005affine}. 
In particular, we aim to use \emph{Algebraic Decision Diagrams (ADDs)} \cite{bahar1997algebraic} for discrete integration, which have been used in stochastic model checking \cite{KNP07} and stochastic planning \cite{HSHB99}. 
An ADD is a compact representation of a real-valued function as a directed acyclic graph. 
% For functions with logical structure, an ADD representation can be exponentially smaller than the explicit representation. 
Moreover, there are several high-performance libraries for efficiently manipulating ADDs \cite{somenzi2015cudd,van2015sylvan}.
ADDs were used for weighted model counting in \addmc{} \cite{DPV20}, which tied for first place of the weighted track of the 2020 Model Counting Competition \cite{fichte2020model}.
While \addmc{} also includes some high-level reasoning, it uses tightly-integrated custom-built heuristics \cite{dechter99,bouquet99,tarjan1984simple,koster2001treewidth} instead of leveraging existing high-level reasoning tools.



% While we do not establish new parameterized complexity results for model counting (as fixed-parameter algorithms for model counting are well-known for a variety of parameters \cite{FMR08,SS10}), we combine these theoretical results with high-performance tensor network libraries and with existing heuristic graph-decomposition tools to produce a competitive tool for weighted model counting.

% The parallelization of neural network training and inference has seen massive research across the machine learning and high-performance computing communities \cite{ABCCDDDGII16,JYPPABBBBB17,PGMLJGKLGA19}. Consequently, GPUs give orders of magnitude of speedup over a single core for neural-network algorithms \cite{KSTKPPRS19,NRBHHJN15}. In this work, we aim to directly leverage advances in multi-core and GPU performance designed for neural-network algorithms in the service of weighted model counting.


% Dynamic programming has also been the basis of several tools for model counting \cite{DPV20,DDV19,dudek2020parallel,fichte2020exploiting}.
% Although each tool uses a different data structure--algebraic decision diagrams (ADDs) \cite{DPV20}, tensors \cite{DDV19,dudek2020parallel}, or database tables \cite{fichte2020exploiting}--the overall algorithms have similar structure.
% % Also, decomposition techniques have seen many applications in model counting, cf.~\cite{jegou2016improving} and the reference therein. %JD: Moved the citation to paragraph 2 instead
% The goal of this work is to unify these approaches into a single conceptual framework: \emph{project-join trees}.
% Project-join trees are not an entirely new idea.
% Similar concepts have been used in constraint programming (as join trees \cite{dechter1989tree}), probabilistic inference (as cluster trees \cite{SAS94}), and database-query optimization (as join-expression trees \cite{MPPV04}).
% Our original contributions include the unification of these concepts into project-join trees and the application of this unifying framework to model counting.



% Over the last ten years, hundreds of thousands of research hours have been poured into low-level computational tools and compilers for neural network training and inference. Simultaneously, there has been a surge in high-level reasoning tools based on graph decompositions, spurred by several competitions. While some existing discrete integration tools (counters) tightly integrate with these low-level computational or high-level reasoning tools, no existing counter is able to leverage both together.

\section{Contributions}

The main contribution of this thesis is a clean separation of dynamic-programming algorithms for discrete integration into a planning phase of high-level reasoning, followed by an execution phase of low-level computation.

We first introduce this separation in a new model counter, \tool{TensorOrder}, which uses graph decompositions for planning and tensors for execution. This includes a new reduction from weighted model counting to tensor network contraction. We consider two planning algorithms-- \textbf{LG} and \textbf{FT}-- based on graph decompositions. While \textbf{LG} is based on existing tensor network (and constraint satisfaction) techniques, we contribute a new analysis that more closely matches the memory usage of existing tensor libraries. \textbf{FT} is a novel planning algorithm, tailored for constrained counting, that factors tensor networks based on tree decompositions.

Next, we show that introducing this separation improves an existing model counter (\tool{ADDMC} \cite{DPV20}). We unify a variety of approaches into a single conceptual framework using project-join trees. We show that replacing the existing constraint-satisfaction planner in \tool{ADDMC} with \textbf{LG} (a planner based on graph decompositions) leads to a faster model counter. Moreover, we compare (dense) tensors (sparse) with algebraic decision diagrams in the execution phase and find that algebraic decision diagrams outperform tensors on single CPU cores.

We next apply this approach in order to develop a parallel model counter by separately parallelizing the planning and execution phases in \tool{TensorOrder}. We parallelize the planning phase by introducing an algorithmic portfolio of planners, motivated by success in the SAT community \cite{XHHL08}. We parallelize the execution phase through the use of parallel tensor libraries. To handle limited-memory environments (e.g., on a GPU), we introduce a novel technique for parallel model counting based on variable marginalization.

Finally, we apply our approach to projected model counting. We present a novel algorithm for performing projected model counting through a planning and execution phase using graded project-join trees. As part of this, we introduce a novel planning algorithm that builds graded project-join trees by using a planner for standard project-join trees as a black-box. The resulting tool \tool{ProCount} makes a significant contribution to a portfolio of exact weighted projected model counters.

\section{Organization}
The remainder of this thesis is organized as follows:

Chapter \ref{ch:background} presents notation and background on model counting, existing high-level planning tools (graph decompositions and heuristics from constraint satisfaction), and existing low-level computational tools (tensors and decision diagrams). 

Chapter \ref{ch:tensors} presents an algorithm for weighted model counting based on tensor networks. The resulting tool \tool{TensorOrder} uses graph decompositions for planning and tensors for execution. Most results in this chapter appear in \cite{DDV19}.

Chapter \ref{ch:dpmc} presents an algorithm for weighted model counting based on project-join trees. The resulting tool \tool{DPMC} uses graph decompositions for planning and decision diagrams for execution. Most results in this chapter appear in \cite{dudek2020dpmc}.

Chapter \ref{ch:parallel} parallelizes the techniques from Chapter \ref{ch:tensors} to run on multiple CPUs, a GPU, and on a TPU. Most results in this chapter appear in \cite{dudek2020parallel}.

Chapter \ref{ch:procount} generalizes the techniques from Chapter \ref{ch:dpmc} to weighted projected model counting. Most results in this chapter appear in \cite{dudek2020procount}.

Finally, Chapter \ref{ch:conclusion} summarizes the main contributions of this thesis and describes several possible future directions.