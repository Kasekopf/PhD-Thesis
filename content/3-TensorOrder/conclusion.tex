\section{Chapter Summary} \label{sec:tensors:conclusion}
We presented a 3-phase algorithm to perform weighted model counting. First, in the reduction phase, a weighted model counting instance is reduced to a tensor-network problem using a novel reduction. Second, in the planning phase, an order to contract tensors in the network is determined. We presented two planning techniques, \textbf{LG} and \textbf{FT}, for using graph decompositions to find contraction trees of small max rank of tensor networks. \textbf{LG} is a general-purpose method for finding contraction orders, while \textbf{FT} is a novel method tailored for constrained counting to handle high-rank, highly-structured tensors. Finally, in the execution phase, tensors in the network are contracted with state-of-the-art tensor libraries using the determined order.


We implemented our algorithm in \tool{TensorOrder}, a new tool for weighted model counting through tensor network contraction.
We evaluated \tool{TensorOrder} in the context of model counting and demonstrated that \textbf{FT} outperforms \textbf{LG} on exact inference benchmarks, and overall \tool{TensorOrder} is able to solve many benchmarks solved by no other (exact) counter.
In particular, \tool{TensorOrder} is the best tool on benchmarks of small carving width.
Thus \tool{TensorOrder} is useful as part of a portfolio of weighted model counters.

% We proved in Corollary \ref{cor:planar-carving} that contraction trees of minimal max rank can be found in cubic time for planar tensor networks. One direction for future work is to implement and evaluate this algorithm in practice on benchmarks of planar tensor networks.

% Projected model counting 
% Bayesian inference problems are often projected