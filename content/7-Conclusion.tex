\chapter{Conclusion and Future Directions}
\label{ch:conclusion}
Discrete integration is a fundamental problem in artificial intelligence, with applications in probabilistic reasoning, planning, inexact computing, engineering reliability, and statistical physics \cite{Bacchus2003,DH07,GSS08,naveh2007constraint}. In discrete integration, the task is to count the total weight, subject to a given weight function, of the set of solutions of input constraints \cite{GSS08}. 
Although discrete integration is theoretically difficult \cite{Valiant79}, the development of tools to compute the total weight on large industrial formulas is an area of active research.

In this thesis, we presented a series of dynamic-programming algorithms and tools for discrete integration based on a single conceptual framework.
Our framework consisted of two cleanly separated phases: a \emph{planning phase} of high-level reasoning, followed by an \emph{execution phase} of low-level computation.
% This explicit separation allowed us to separately reason about, implement, and optimize each phase.
We showed how to leverage existing graph decomposition tools for the planning phase.
Similarly, we showed how to leverage existing computational libraries for the execution phase.
The resulting tools scale to large instances of discrete integration problems and run flexibly in a variety of hardware environments.

We introduced this framework in Chapter \ref{ch:tensors} with a new counter, \tool{TensorOrder}, which used graph decompositions for planning and tensor libraries for execution.
To enable the use of tensor libraries, we presented a new reduction from weighted model counting to tensor network contraction. 
We analyzed two planning techniques-- an existing approach \textbf{LG} and a new approach \textbf{FT}-- that use graph decompositions to find contraction trees of small max rank of tensor networks.
\tool{TensorOrder}, when equipped with the \textbf{FT} planner, was the best tool on discrete integration benchmarks of small carving width.

We then applied this framework in Chapter \ref{ch:dpmc} to an existing model counter, \tool{ADDMC} \cite{DPV20,phan2019weighted}.
We unified a variety of discrete-integration approaches, including \tool{ADDMC}, into a single conceptual framework the uses project-join trees to separate planning and execution.
We showed that replacing the existing constraint-satisfaction planner in \tool{ADDMC} with \textbf{LG} (a planner based on graph decompositions) led to a faster model counter. 
Moreover, we compared (dense) tensors with (sparse) algebraic decision diagrams in the execution phase and found that algebraic decision diagrams outperform tensors on single CPU cores.
The resulting tool \tool{DPMC} was the fastest solver on a significant number of benchmarks and thus is valuable as part of a portfolio of counters.

Next, in Chapter \ref{ch:parallel} we exploited our framework to develop a parallel model counter by separately parallelizing the planning and execution phases in \tool{TensorOrder}.
We showed that the planning phase may be parallelized by using an algorithmic portfolio \cite{XHHL08} of planners.
Further, we showed that the execution phase may be parallelized through parallel tensor libraries.
In order to handle limited-memory environments (e.g., on a GPU), we introduced index slicing to divide the computation of a single tensor network contraction.
Although we showed that index slicing also allows for efficient tensor network contraction on a TPU theoretically, in practice we observed that current tensor libraries fail to compile tensor computations with high-dimensional tensors to a TPU.
The resulting tool \tool{TensorOrder2} was the fastest parallel model counter on a significant number of benchmarks.

Finally, in Chapter \ref{ch:procount} we applied our framework to projected model counting by extending the approach in Chapter \ref{ch:dpmc}.
We presented a novel algorithm for performing projected model counting through a planning and execution phase using graded project-join trees.
Our key theoretical contribution was a novel algorithm to construct graded project-join trees from standard project-join trees.
The resulting tool \tool{ProCount} made a significant contribution to a portfolio of exact weighted projected model counters.

Overall, we demonstrated that a clean separation of dynamic-programming algorithms for discrete integration into a planning phase of high-level reasoning, followed by an execution phase of low-level computation yielded algorithms and tools for discrete integration that scale to large instance and run flexibly in a variety of configurations and hardware environments.

\section{Future Work}
The framework of planning and execution introduced in this thesis is just the next step towards developing practical tools for automated reasoning.
We end with a list of several open directions to improve this framework and to apply this framework in broader context.

% \subsection{Understanding Performance and Limitations}
% One direction for future work is to improve our understanding of the performance of our dynamic-programming-based methods.  

% In this thesis, we focused on heuristic graph decomposition tools, which aim to find ``good-enough'' graph decompositions. It would be interesting in the future to analyze the types of benchmarks amenable to tensor-network methods, e.g. by computing lower bounds on carving width in addition to the upper bounds given by heuristic methods. 

\subsection{Improving Planning}
The planning approaches in this thesis were explicitly designed to take advantage of existing graph decomposition tools in an unmodified, black-box way.
Future improvements to graph decomposition tools, itself an active area of research, may allow us to scale to larger benchmarks.
Moreover, developing customized graph decomposition tools for planning in discrete integration is a promising avenue for future work.

While this thesis evaluated a subset of graph decomposition tools for planning, one easy avenue for improvement of our tools is to consider other graph decomposition tools.
Integrating a diverse set of graph decomposition tools would especially benefit a portfolio of planners, as in Chapter \ref{ch:parallel}.
For example, there has been work on parallel branch decomposition tools \cite{hicks2000branch}.
It may also be possible to exploit other types of graph decompositions (e.g. hypertree decompositions \cite{AGG07}) for planning.

The parallel portfolio of planners that we developed in Chapter \ref{ch:parallel} that was functional but simplistic.
It may be possible to improve the portfolio through more advanced algorithm-selection techniques \cite{HHLKS09,XHHL12}. 
% One could also develop parallel heuristic decomposition solvers directly, e.g., by adapting the exact GPU-based tree-decomposition solver \cite{VB17} into a heuristic solver.
This portfolio planner may be useful to apply in other planning contexts, for example to projected model counting in Chapter \ref{ch:procount}.
More broadly, this portfolio strategy could be useful to parallelize a variety of applications that use graph decomposition tools.


\subsection{Improving Execution}
Similar to planning, the execution approaches in this thesis were explicitly designed to take advantage of existing tensor and ADD libraries in an unmodified, black-box way.
Future improvements to these computational libraries, which is itself an extremely active area of independent research in high-performance computing, may allow us to scale to larger benchmarks in the future.
Moreover, developing computational libraries that are specifically optimized for execution in discrete integration is a promising avenue for future work.
A problem of particular interest is to re-engineer the XLA compiler when targeting a TPU in order to handle the high-dimensional tensors seen in model counting.
One could also consider implementing our execution algorithms using other computational libraries, e.g. using databases as in \cite{fichte2020exploiting}, using the parallel ADD library \sylvan{} \cite{van2015sylvan}, or using other sparse data structures \cite{sanner2005affine,li2018hicoo}. %TODO: more citations?

In Chapter \ref{ch:parallel}, we evaluated index slicing in the context of tensor-based execution.
One avenue for future development of parallel counters is to integrate slicing with the ADD-based execution from Chapter \ref{ch:dpmc} or Chapter \ref{ch:procount}.
This may require more complex techniques for choosing which indices (i.e., variables) to slice, since it is difficult to estimate the memory usage of (sparse) ADDs a priori.

Moreover, we focused on contracting all tensor network slices in sequence on a single GPU.
There are opportunities in future work to apply index slicing in more complex ways to leverage parallelism at a larger scale. 
One potential approach is to run each slice computation in Algorithm \ref{alg:tn-sliced} in parallel on a separate CPU core, on a separate GPU, or even on entirely separate nodes in a computing cluster.
For example, recent work in the tensor network community used index slicing to divide a single tensor network contraction across a computing cluster containing over 100k CPU cores running in parallel \cite{CZHNS18}.
Such techniques would allow our framework to scale to leverage huge computational resources for difficult discrete integration benchmarks.


\subsection{Beyond CNF Formulas}
While we focused on discrete integration over CNF formulas, many of the techniques in this thesis easily extend to discrete integration over more general classes of constraints.
For example, all techniques we introduced in this work would have similar performance when applied to formulas that mix CNF clauses (i.e., OR clauses) with XOR clauses and Exactly-One clauses. % (as such clauses can also be represented as tree-factorable tensors).
The techniques from Chapter \ref{ch:dpmc} and \ref{ch:procount} require only that the discrete integration query is presented as the conjunction of constraints, but need no restriction on the type of each constraint. 
In contrast, techniques for discrete integration based on search or knowledge compilation often require different reasoning techniques for each type of constraint (or requires the constraints to be encoded as a CNF formula, which may dramatically increase the size of of the constraints).
Evaluating our techniques on a wider collection of benchmarks is an exciting direction for future work that may enable new applications of discrete integration.

%  More generally, our algorithms for tensor-network contraction can be used to improve many other applications of tensor networks, e.g. quantum circuit simulation \cite{MS08}.

\subsection{Beyond Discrete Integration}
The focus in this thesis is on processing a single discrete integration query. 
In many applications, however, several discrete integration queries are made with an identical or similar set of constraints.
Such repeated queries are handled well by counters based on knowledge compilation, where the same set of compiled constraints can be queried multiple times \cite{koriche2013knowledge,LM17,darwiche2004new,OD15}.
Exploring how dynamic programming can be leveraged to handle several queries is another promising research direction.
For example, in some contexts one could reuse the same execution plan from the planning stage across multiple discrete integration queries.

Our framework of planning and execution can be used as a guide and applied to other problems beyond discrete integration.
For example, Tabajara and Vardi \cite{tabajara2017factored} described a dynamic-programming, decision-diagram-based framework for functional Boolean synthesis.
Refactoring the algorithm into a planning phase followed by an execution phase is also of interest in that context to produce more scalable and flexible tools.
Our framework could also be generalized for maximum model counting \cite{fremont2017maximum} and other types of functional aggregate queries (FAQs) \cite{KNR16}, including MAP \cite{murphy2012machine,maua2015complexity,xue2016solving}.
